{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import time\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "path_df = \"C:/Users/migue/Data Science/Master Data Science/KSCHOOL/9. TFM/0. Latest News Classifier/03. Feature Engineering/Pickles/df.pickle\"\n",
    "with open(path_df, 'rb') as data:\n",
    "    df = pickle.load(data)\n",
    "    \n",
    "# X_train\n",
    "path_X_train = \"C:/Users/migue/Data Science/Master Data Science/KSCHOOL/9. TFM/0. Latest News Classifier/03. Feature Engineering/Pickles/X_train.pickle\"\n",
    "with open(path_X_train, 'rb') as data:\n",
    "    X_train = pickle.load(data)\n",
    "\n",
    "# X_test\n",
    "path_X_test = \"C:/Users/migue/Data Science/Master Data Science/KSCHOOL/9. TFM/0. Latest News Classifier/03. Feature Engineering/Pickles/X_test.pickle\"\n",
    "with open(path_X_test, 'rb') as data:\n",
    "    X_test = pickle.load(data)\n",
    "\n",
    "# y_train\n",
    "path_y_train = \"C:/Users/migue/Data Science/Master Data Science/KSCHOOL/9. TFM/0. Latest News Classifier/03. Feature Engineering/Pickles/y_train.pickle\"\n",
    "with open(path_y_train, 'rb') as data:\n",
    "    y_train = pickle.load(data)\n",
    "\n",
    "# y_test\n",
    "path_y_test = \"C:/Users/migue/Data Science/Master Data Science/KSCHOOL/9. TFM/0. Latest News Classifier/03. Feature Engineering/Pickles/y_test.pickle\"\n",
    "with open(path_y_test, 'rb') as data:\n",
    "    y_test = pickle.load(data)\n",
    "\n",
    "# features_train\n",
    "path_features_train = \"C:/Users/migue/Data Science/Master Data Science/KSCHOOL/9. TFM/0. Latest News Classifier/03. Feature Engineering/Pickles/features_train.pickle\"\n",
    "with open(path_features_train, 'rb') as data:\n",
    "    features_train = pickle.load(data)\n",
    "\n",
    "# labels_train\n",
    "path_labels_train = \"C:/Users/migue/Data Science/Master Data Science/KSCHOOL/9. TFM/0. Latest News Classifier/03. Feature Engineering/Pickles/labels_train.pickle\"\n",
    "with open(path_labels_train, 'rb') as data:\n",
    "    labels_train = pickle.load(data)\n",
    "\n",
    "# features_test\n",
    "path_features_test = \"C:/Users/migue/Data Science/Master Data Science/KSCHOOL/9. TFM/0. Latest News Classifier/03. Feature Engineering/Pickles/features_test.pickle\"\n",
    "with open(path_features_test, 'rb') as data:\n",
    "    features_test = pickle.load(data)\n",
    "\n",
    "# labels_test\n",
    "path_labels_test = \"C:/Users/migue/Data Science/Master Data Science/KSCHOOL/9. TFM/0. Latest News Classifier/03. Feature Engineering/Pickles/labels_test.pickle\"\n",
    "with open(path_labels_test, 'rb') as data:\n",
    "    labels_test = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1891, 300)\n",
      "(334, 300)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(features_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation for Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we can see what hyperparameters the model has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'C': 1.0,\n",
      " 'cache_size': 200,\n",
      " 'class_weight': None,\n",
      " 'coef0': 0.0,\n",
      " 'decision_function_shape': 'ovr',\n",
      " 'degree': 3,\n",
      " 'gamma': 'auto',\n",
      " 'kernel': 'rbf',\n",
      " 'max_iter': -1,\n",
      " 'probability': False,\n",
      " 'random_state': 8,\n",
      " 'shrinking': True,\n",
      " 'tol': 0.001,\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "svc_0 =svm.SVC(random_state=8)\n",
    "\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(svc_0.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll tune the following ones:\n",
    "\n",
    "* `C`: \n",
    "* \n",
    "* \n",
    "* \n",
    "* \n",
    "\n",
    "**COMPLETAR**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to define the grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': [0.0001, 0.001, 0.01],\n",
      " 'degree': [1, 2, 3, 4, 5],\n",
      " 'gamma': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
      " 'kernel': ['linear', 'rbf', 'poly']}\n"
     ]
    }
   ],
   "source": [
    "# C\n",
    "C = [.0001, .001, .01]\n",
    "\n",
    "# gamma\n",
    "gamma = [.0001, .001, .01, .1, 1, 10, 100]\n",
    "\n",
    "# degree\n",
    "degree = [1, 2, 3, 4, 5]\n",
    "\n",
    "# kernel\n",
    "kernel = ['linear', 'rbf', 'poly']\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'C': C,\n",
    "              'kernel': kernel,\n",
    "              'gamma': gamma,\n",
    "              'degree': degree\n",
    "             }\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll perform the Random Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:  5.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=8, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          fit_params=None, iid=True, n_iter=50, n_jobs=1,\n",
       "          param_distributions={'C': [0.0001, 0.001, 0.01], 'kernel': ['linear', 'rbf', 'poly'], 'gamma': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100], 'degree': [1, 2, 3, 4, 5]},\n",
       "          pre_dispatch='2*n_jobs', random_state=8, refit=True,\n",
       "          return_train_score='warn', scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First create the base model to tune\n",
    "svc = svm.SVC(random_state=8)\n",
    "\n",
    "# Definition of the random search\n",
    "random_search = RandomizedSearchCV(estimator=svc,\n",
    "                                   param_distributions=random_grid,\n",
    "                                   n_iter=50,\n",
    "                                   scoring='accuracy',\n",
    "                                   cv=3, \n",
    "                                   verbose=1, \n",
    "                                   random_state=8)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'poly', 'gamma': 10, 'degree': 4, 'C': 0.01}\n",
      "0.9212057112638815\n"
     ]
    }
   ],
   "source": [
    "print(random_search.best_params_)\n",
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we can do a more exhaustive search centered in those values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  84 out of  84 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=8, test_size=0.33, train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=8, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': [0.0001, 0.001, 0.01, 0.1], 'kernel': ['linear']}, {'C': [0.0001, 0.001, 0.01, 0.1], 'kernel': ['poly'], 'degree': [3, 4, 5]}, {'C': [0.0001, 0.001, 0.01, 0.1], 'kernel': ['rbf'], 'gamma': [1, 10, 100]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "C = [.0001, .001, .01, .1]\n",
    "degree = [3, 4, 5]\n",
    "gamma = [1, 10, 100]\n",
    "\n",
    "param_grid = [\n",
    "  {'C': C, 'kernel':['linear']},\n",
    "  {'C': C, 'kernel':['poly'], 'degree':degree},\n",
    "  {'C': C, 'kernel':['rbf'], 'gamma':gamma }\n",
    "]\n",
    "\n",
    "# Create a base model\n",
    "svc = svm.SVC(random_state=8)\n",
    "\n",
    "# Manually create the splits in CV in order to be able to fix a random_state (GridSearchCV doesn't have that argument)\n",
    "cv_sets = ShuffleSplit(n_splits = 3, test_size = .33, random_state = 8)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=svc, \n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=cv_sets,\n",
    "                           verbose=1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameters turn out to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'kernel': 'linear'}\n",
      "0.9498666666666666\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svc = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=8, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now know the best SVM model. Let's fit it and see how it performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=8, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svc.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pred = best_svc.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For performance, we'll analyze the confusion matrix, the classification report and the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: \n",
      "0.9592808038075092\n",
      "-------------------------------------------------------------------------\n",
      "The test accuracy is: \n",
      "0.9401197604790419\n",
      "-------------------------------------------------------------------------\n",
      "Classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.92        81\n",
      "          1       0.96      0.94      0.95        49\n",
      "          2       0.97      0.89      0.93        72\n",
      "          3       0.99      0.99      0.99        72\n",
      "          4       0.93      0.90      0.92        60\n",
      "\n",
      "avg / total       0.94      0.94      0.94       334\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "Confusion matrix\n",
      "[[79  0  1  0  1]\n",
      " [ 2 46  1  0  0]\n",
      " [ 5  0 64  0  3]\n",
      " [ 0  1  0 71  0]\n",
      " [ 4  1  0  1 54]]\n",
      "-------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Training accuracy\n",
    "print(\"The training accuracy is: \")\n",
    "print(accuracy_score(labels_train, best_svc.predict(features_train)))\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "\n",
    "# Test accuracy\n",
    "print(\"The test accuracy is: \")\n",
    "print(accuracy_score(labels_test, svc_pred))\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification report\")\n",
    "print(classification_report(labels_test,svc_pred))\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion matrix\")\n",
    "print(confusion_matrix(labels_test,svc_pred))\n",
    "print(\"-------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the hyperparameter tuning process has been useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2155688622754491"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = svm.SVC(random_state = 8)\n",
    "base_model.fit(features_train, labels_train)\n",
    "accuracy_score(labels_test, base_model.predict(features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9401197604790419"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svc.fit(features_train, labels_train)\n",
    "accuracy_score(labels_test, best_svc.predict(features_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Models/best_svc.pickle', 'wb') as output:\n",
    "    pickle.dump(best_svc, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
